{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8e09f8-282a-4f67-9683-0229480c75dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 'test.csv' berhasil diunduh.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "# Download dataset helpdesk TIK UB\n",
    "url = 'https://docs.google.com/spreadsheets/d/1PzUlTZwY6IySZ7VNotDIH3h9hnuRIuy40CgAS7BcFkE/export?gid=1874021283&format=csv'\n",
    "output_file = 'test.csv'\n",
    "\n",
    "urllib.request.urlretrieve(url, output_file)\n",
    "\n",
    "print(f\"File '{output_file}' berhasil diunduh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea26aa4-145c-4eab-a360-bfb2e2c8c762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatahap27/.conda/envs/NER-Project/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec76b943-782e-46f0-92bd-b52c05aff0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_target_domain = pd.read_csv('test.csv', usecols=['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ea412c-6cf2-43e9-a98e-fa9e741df978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14605"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_target_domain['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a6ba73-043e-4ab9-9a1a-20a122594a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9619"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_target_domain['body'] = dataset_target_domain['body']\n",
    "dataset_target_domain = dataset_target_domain.drop_duplicates(subset='body')\n",
    "dataset_target_domain = dataset_target_domain.reset_index(drop=True)\n",
    "# dataset_target_domain['body'] = dataset_target_domain['body'].apply(list)\n",
    "len(dataset_target_domain['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "086397d1-9b3f-4ac2-8769-1dc9ae19c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tag(x):\n",
    "    if x is not None:\n",
    "        # Menghilangkan tag blockquote beserta isinya\n",
    "        text_no_blockquote = re.sub(r'<blockquote>.*?</blockquote>', '', x, flags=re.DOTALL)\n",
    "        \n",
    "        # Menghilangkan tag HTML\n",
    "        text_no_html = re.sub(r'<[^>]+>', '', text_no_blockquote)\n",
    "        \n",
    "        return text_no_html\n",
    "    return None\n",
    "\n",
    "def remove_blockquote_tag(sentence):\n",
    "    if sentence is not None:\n",
    "        return re.sub(r'<blockquote>.*?</blockquote>', '', sentence, flags=re.DOTALL)\n",
    "    return None\n",
    "\n",
    "def remove_html_tag(x):\n",
    "    if x is not None:\n",
    "        return re.sub(r'<[^>]+>', '', x)\n",
    "    return None\n",
    "\n",
    "dataset_target_domain['body'] = dataset_target_domain['body'].apply(remove_blockquote_tag)\n",
    "dataset_target_domain['body'] = dataset_target_domain['body'].apply(remove_html_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da2d6f5-096e-4b86-bd67-f360fea2acd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 12:25:34.992539: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-20 12:25:34.992626: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-20 12:25:34.993790: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-20 12:25:35.001172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 12:25:36.068927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers.generation import TFGenerationMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83c329e-199c-4d18-bcbd-deec6d9b8a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b558c3dc-00a0-4271-8988-d92f727e1405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bryanahusna/my-nergrit-model\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"bryanahusna/my-nergrit-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c630294e-d0e5-4ad0-aaa5-b1b8a2ee4b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['berbahasa', 'indonesia', ',', 'pada', 'tanggal', '27', 'september', '202', '##2', '09', ':', '46']\n",
      "12\n",
      "\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "\n",
      "tensor([[38, 38,  4, 38, 38, 38,  1, 20, 20, 20, 17, 36, 36, 38],\n",
      "        [38, 38, 38, 10, 38, -1, -1, -1, -1, -1, -1, -1, -1, -1]])\n",
      "torch.Size([2, 14])\n",
      "\n",
      "{'input_ids': tensor([[    3,  6196,  1718,    16,  1560,  2307,  3402,  3264, 24674,   952,\n",
      "          8336,    30,  6631,     4],\n",
      "        [    3,  1540,  5859,  2048,     4,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "tes = [\"berbahasa Indonesia, pada tanggal 27 September 2022 09:46\", \"ini kalimat kedua\"]\n",
    "\n",
    "tes2 = tokenizer(tes, padding=True, return_tensors='pt')\n",
    "token = tokenizer.tokenize(tes[0])\n",
    "\n",
    "attention_mask = tes2['attention_mask']\n",
    "\n",
    "output = model(**tes2)\n",
    "logits = output.logits\n",
    "\n",
    "predicted = torch.argmax(logits, dim=2)\n",
    "predicted = predicted_tes.masked_fill(attention_mask==0, -1)\n",
    "\n",
    "print(token)\n",
    "print(len(token))\n",
    "print()\n",
    "\n",
    "print(tes2['attention_mask'])\n",
    "print()\n",
    "\n",
    "print(predicted)\n",
    "print(predicted.size())\n",
    "print()\n",
    "\n",
    "print(tes2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel1",
   "language": "python",
   "name": "kernel1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
