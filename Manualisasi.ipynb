{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086d3fed-568b-4395-919b-d0cfaddf1692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import torch\n",
    "import json\n",
    "import fasttext\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9be463b-012c-4121-b9ac-3cf03be2bdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7293661-18a0-49f7-8f52-ad9202e83abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "id_fasttext = fasttext.load_model('./cc.id.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7eebf91-fcf8-4c63-8fbc-e113f13aae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 2\n",
    "hidden_size = 2\n",
    "expert_output_size = 1\n",
    "ner_tags = [i for i in range(39)]\n",
    "n_heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b369d01-7037-4733-8e30-225e35b4a6c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fasttext.FastText._FastText at 0x7fd610209fd0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext.util.reduce_model(id_fasttext,embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "34354df1-fb53-4946-a305-7b16e01d2001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.04448834, 0.00509501], dtype=float32),\n",
       " array([0.3491381 , 0.03814312], dtype=float32),\n",
       " array([0.06721243, 0.03095353], dtype=float32),\n",
       " array([-0.6374125,  1.3449613], dtype=float32)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['Gempa', 'bumi', 'berkekuatan', '5']\n",
    "t_labels = [38,38,38,15]\n",
    "\n",
    "data_test = ['Gempa', 'bumi', 'berkekuatan', '75']\n",
    "\n",
    "data_vector = [id_fasttext[w] for w in data]\n",
    "data_test = torch.stack([torch.stack([torch.Tensor(id_fasttext[w]) for w in data_test])])\n",
    "\n",
    "data_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fda3e10e-c1f1-4576-b0ac-98766178f54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3264460/1405000441.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_data = pad_sequence([torch.tensor(seq) for seq in data], batch_first=True, padding_value=torch.nan)\n",
      "/tmp/ipykernel_3264460/1405000441.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(padded_data)\n"
     ]
    }
   ],
   "source": [
    "data = [data_vector]\n",
    "\n",
    "length = torch.Tensor([1])\n",
    "\n",
    "length, sort_idx = torch.sort(length, descending=True)\n",
    "data = [data[i] for i in sort_idx]\n",
    "\n",
    "data = [torch.Tensor(seq).float().to(device).clone().detach() for seq in data]\n",
    "\n",
    "def padding(data):\n",
    "    padded_data = pad_sequence([torch.tensor(seq) for seq in data], batch_first=True, padding_value=torch.nan)\n",
    "    return torch.tensor(padded_data)\n",
    "\n",
    "data = padding(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4842efd0-1812-474d-899d-e187cd86437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Forward forget gate\n",
    "        self.W_ffx = nn.Parameter(torch.Tensor(hidden_size, embedding_size))\n",
    "        self.b_ffx = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.W_ffh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_ffh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # Forward cell gate\n",
    "        self.W_cfx = nn.Parameter(torch.Tensor(hidden_size, embedding_size))\n",
    "        self.b_cfx = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.W_cfh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_cfh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # Forward input gate\n",
    "        self.W_ifx = nn.Parameter(torch.Tensor(hidden_size, embedding_size))\n",
    "        self.b_ifx = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.W_ifh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_ifh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # Forward output gate\n",
    "        self.W_ofx = nn.Parameter(torch.Tensor(hidden_size, embedding_size))\n",
    "        self.b_ofx = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.W_ofh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_ofh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "\n",
    "        # Backward forget gate\n",
    "        self.W_fbx = nn.Parameter(torch.Tensor(hidden_size, embedding_size))\n",
    "        self.b_fbx = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.W_fbh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_fbh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # backward cell gate\n",
    "        self.W_cbx = nn.Parameter(torch.Tensor(hidden_size, embedding_size))\n",
    "        self.b_cbx = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.W_cbh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_cbh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # Backward input gate\n",
    "        self.W_ibx = nn.Parameter(torch.Tensor(hidden_size, embedding_size))\n",
    "        self.b_ibx = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.W_ibh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_ibh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # Backward output gate\n",
    "        self.W_obx = nn.Parameter(torch.Tensor(hidden_size, embedding_size))\n",
    "        self.b_obx = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        self.W_obh = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n",
    "        self.b_obh = nn.Parameter(torch.Tensor(hidden_size))\n",
    "        \n",
    "        # is it better or reset every sentece is better?\n",
    "        self.reset_states()\n",
    "        \n",
    "        # Set init weight to normal\n",
    "        for name,p in self.named_parameters():\n",
    "            nn.init.normal_(p)\n",
    "            \n",
    "    def reset_states(self):\n",
    "        self.h_fx = torch.zeros(self.hidden_size, device=device)\n",
    "        self.c_fx = torch.zeros(self.hidden_size, device=device)\n",
    "        self.h_bx = torch.zeros(self.hidden_size, device=device)\n",
    "        self.c_bx = torch.zeros(self.hidden_size, device=device)\n",
    "\n",
    "    def forward(self, x, verbose):\n",
    "        ''' BiLSTM forward\n",
    "        Args:\n",
    "            x (list of tensor): vectorize sentence that has been padded\n",
    "        Returns:\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.reset_states()\n",
    "        \n",
    "        # Lists to store outputs\n",
    "        outputs_fx, outputs_bx = [], []\n",
    "\n",
    "        # Forward pass\n",
    "        for i, x_i in enumerate(x):\n",
    "            o_seq = []\n",
    "            p_f = []\n",
    "            p2_f = []\n",
    "            p_ft = []\n",
    "            p_it = []\n",
    "            p_ot = []\n",
    "            p_gt = []\n",
    "            \n",
    "            for t in range(x_i.size(0)):\n",
    "                x_t = x[i][t]\n",
    "                \n",
    "                if all(x_t.isnan()):\n",
    "                    o_seq.append(torch.zeros(self.hidden_size).to(device))\n",
    "                    continue\n",
    "\n",
    "                # Forward LSTM\n",
    "                f_t = torch.sigmoid(x_t @ self.W_ffx.t() + self.b_ffx + self.h_fx @ self.W_ffh.t() + self.b_ffh)\n",
    "                i_t = torch.sigmoid(x_t @ self.W_ifx.t() + self.b_ifx + self.h_fx @ self.W_ifh.t() + self.b_ifh)\n",
    "                o_t = torch.sigmoid(x_t @ self.W_ofx.t() + self.b_ofx + self.h_fx @ self.W_ofh.t() + self.b_ofh)\n",
    "                g_t = torch.tanh(x_t @ self.W_cfx.t() + self.b_cfx + self.h_fx @ self.W_cfh.t() + self.b_cfh)\n",
    "\n",
    "                self.c_fx = f_t * self.c_fx + i_t * g_t\n",
    "                self.h_fx = o_t * torch.tanh(self.c_fx)\n",
    "    \n",
    "                p_f.append(self.c_fx)\n",
    "                p2_f.append(self.h_fx)\n",
    "                p_ft.append(f_t)\n",
    "                p_it.append(i_t)\n",
    "                p_ot.append(o_t)\n",
    "                p_gt.append(g_t)\n",
    "                o_seq.append(self.h_fx)\n",
    "            \n",
    "            outputs_fx.append(torch.stack(o_seq))\n",
    "            \n",
    "        # Backward pass\n",
    "        for i, x_i in enumerate(x):\n",
    "            o_seq = []\n",
    "            p_b = []\n",
    "            p2_b = []\n",
    "            pb_ft = []\n",
    "            pb_it = []\n",
    "            pb_ot = []\n",
    "            pb_gt = []\n",
    "            \n",
    "            for t in range(x_i.size(0) - 1, -1, -1):\n",
    "                x_t = x[i][t]\n",
    "                \n",
    "                if all(x_t.isnan()):\n",
    "                    o_seq.append(torch.zeros(self.hidden_size).to(device))\n",
    "                    continue\n",
    "\n",
    "                # Backward LSTM\n",
    "                f_t = torch.sigmoid(x_t @ self.W_fbx.t() + self.b_fbx + self.h_bx @ self.W_fbh.t() + self.b_fbh)\n",
    "                i_t = torch.sigmoid(x_t @ self.W_ibx.t() + self.b_ibx + self.h_bx @ self.W_ibh.t() + self.b_ibh)\n",
    "                o_t = torch.sigmoid(x_t @ self.W_obx.t() + self.b_obx + self.h_bx @ self.W_obh.t() + self.b_obh)\n",
    "                g_t = torch.tanh(x_t @ self.W_cbx.t() + self.b_cbx + self.h_bx @ self.W_cbh.t() + self.b_cbh)\n",
    "\n",
    "                self.c_bx = f_t * self.c_bx + i_t * g_t\n",
    "                self.h_bx = o_t * torch.tanh(self.c_bx)\n",
    "                \n",
    "                p2_b.append(self.h_bx)\n",
    "                p_b.append(self.c_bx)\n",
    "                pb_ft.append(f_t)\n",
    "                pb_it.append(i_t)\n",
    "                pb_ot.append(o_t)\n",
    "                pb_gt.append(g_t)\n",
    "                o_seq.append(self.h_bx)\n",
    "                    \n",
    "            p_b.reverse()\n",
    "            p2_b.reverse()\n",
    "            pb_ft.reverse()\n",
    "            pb_it.reverse()\n",
    "            pb_ot.reverse()\n",
    "            pb_gt.reverse()\n",
    "            \n",
    "            o_seq.reverse()\n",
    "            outputs_bx.append(torch.stack(o_seq))\n",
    "        \n",
    "        outputs_fx = torch.stack(outputs_fx)\n",
    "        outputs_bx = torch.stack(outputs_bx)\n",
    "        \n",
    "        # Concatenate hidden states from both directions\n",
    "        outputs = torch.cat([outputs_fx, outputs_bx],2)\n",
    "        \n",
    "        if(verbose):\n",
    "            print(\"================ BiLSTM ================\")\n",
    "            print()\n",
    "            \n",
    "            for name, p in self.named_parameters():\n",
    "                print(name)\n",
    "                print(p)\n",
    "                print()\n",
    "            \n",
    "            print(\"Forget Gate Forward:\")\n",
    "            print(torch.stack(p_ft))\n",
    "\n",
    "            print(\"\\nForget Gate Backward:\")\n",
    "            print(torch.stack(pb_ft))\n",
    "\n",
    "            print(\"\\nIpnut Gate Forward:\")\n",
    "            print(torch.stack(p_it))\n",
    "\n",
    "            print(\"\\nInput Gate Backward:\")\n",
    "            print(torch.stack(pb_it))\n",
    "\n",
    "            print(\"\\nOutput Gate Forward:\")\n",
    "            print(torch.stack(p_ot))\n",
    "\n",
    "            print(\"\\nOutput Gate Backward:\")\n",
    "            print(torch.stack(pb_ot))\n",
    "\n",
    "            print(\"\\nCell Gate Forward:\")\n",
    "            print(torch.stack(p_gt))\n",
    "\n",
    "            print(\"\\nCell Gate Backward:\")\n",
    "            print(torch.stack(pb_gt))\n",
    "\n",
    "            print(\"\\nCell Output Forward:\")\n",
    "            print(torch.stack(p_f))\n",
    "\n",
    "            print(\"\\nCell Output Backward:\")\n",
    "            print(torch.stack(p_b))\n",
    "\n",
    "            print(\"\\nHidden State Forward:\")\n",
    "            print(torch.stack(p2_f))\n",
    "\n",
    "            print(\"\\nHidden State Backward:\")\n",
    "            print(torch.stack(p2_b))\n",
    "            \n",
    "            print(\"\\nConcatened hidden State:\")\n",
    "            print(outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d215c562-7114-4a24-a055-5b1a796bdd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.Q = nn.Linear(hidden_size*2, input_size)\n",
    "        self.K = nn.Linear(input_size, input_size)\n",
    "        self.V = nn.Linear(input_size, input_size)\n",
    "        \n",
    "        for name, p in self.named_parameters():\n",
    "            nn.init.normal_(p)\n",
    "    \n",
    "    def forward(self, q, k, v, verbose):\n",
    "        q = self.Q(q)\n",
    "        k = self.K(k)\n",
    "        v = self.V(v)\n",
    "        \n",
    "        # matmul q k\n",
    "        q_k = torch.bmm(q,k.transpose(1,2))/torch.sqrt(torch.Tensor([self.input_size]).to(device)) # :39\n",
    "        q_k_softmax = F.softmax(q_k, dim=-1)\n",
    "        \n",
    "        # matmul o v\n",
    "        o = torch.bmm(q_k_softmax, v)\n",
    "        \n",
    "        if verbose:\n",
    "            print('=================== Attention ===================\\n')\n",
    "            for name, p in self.named_parameters():\n",
    "                print(name)\n",
    "                print(p)\n",
    "                print()\n",
    "                \n",
    "            print('Query')\n",
    "            print(q)\n",
    "            print()\n",
    "            \n",
    "            print('Key')\n",
    "            print(k)\n",
    "            print()\n",
    "            \n",
    "            print('Key')\n",
    "            print(v)\n",
    "            print()\n",
    "            \n",
    "            print('softmax Q K')\n",
    "            print(q_k_softmax)\n",
    "            print()\n",
    "            \n",
    "            print('O V')\n",
    "            print(o)\n",
    "            print()\n",
    "            \n",
    "        \n",
    "        return o\n",
    "\n",
    "class MultiheadAttentionGate(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_head, ner_nums):\n",
    "        \"\"\"\n",
    "            input size is output_expert_size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        self.attentions = nn.ModuleList(AttentionGate(input_size*ner_nums, hidden_size) for _ in range(n_head))\n",
    "        \n",
    "        # output MoEE tidak harus sesuai dengan jumlah tag\n",
    "        self.classifiers = nn.Linear(input_size*n_head*ner_nums, ner_nums)\n",
    "        \n",
    "        for name, p in self.named_parameters():\n",
    "            nn.init.normal_(p)\n",
    "        \n",
    "    def forward(self, x, bi_lstm_o, verbose):\n",
    "        o_a = []\n",
    "        \n",
    "        for i, att in enumerate(self.attentions):\n",
    "            if i == 0: o = att(bi_lstm_o,x,x,verbose)\n",
    "            else: o = att(bi_lstm_o,x,x,False)\n",
    "            \n",
    "            o_a.append(o)\n",
    "            \n",
    "        concatened_o = torch.cat(o_a,2)\n",
    "        outputs = self.classifiers(concatened_o)\n",
    "        \n",
    "        if(verbose):\n",
    "            print('================ Multihead Attention ================')\n",
    "            print()\n",
    "            \n",
    "            for name, p in self.named_parameters():\n",
    "                print(name)\n",
    "                print(p)\n",
    "                print()\n",
    "            \n",
    "            print(\"cat head\")\n",
    "            print(concatened_o)\n",
    "            print()\n",
    "            \n",
    "            print(\"outputs\")\n",
    "            print(outputs)\n",
    "            print()\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93295e6c-add3-4065-87b0-420dc65253ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoEE(nn.Module):\n",
    "    def __init__(self, ner_tags, hidden_size, expert_output_size, n_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.experts = nn.ModuleList([EntityExpert(hidden_size, expert_output_size) for _ in range(len(ner_tags))])\n",
    "        \n",
    "        # gate dilewatkan ke dropout terlebih dahulu\n",
    "        \n",
    "        self.gate = MultiheadAttentionGate(expert_output_size, hidden_size, n_heads, len(ner_tags))\n",
    "    \n",
    "    def forward(self, x, verbose):\n",
    "        e_o = []\n",
    "        \n",
    "        for e in self.experts:\n",
    "            e_output = e(x)\n",
    "            e_o.append(e_output)\n",
    "            \n",
    "        outputs = torch.cat(e_o,2)   \n",
    "        \n",
    "        outputs = self.gate(outputs,x,verbose)\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "class EntityExpert(nn.Module):\n",
    "    def __init__(self, hidden_state_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.entity_expert = nn.Linear(2*hidden_state_size, output_size)\n",
    "        \n",
    "        for name, p in self.named_parameters():\n",
    "            nn.init.normal_(p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.entity_expert(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fab80a83-6228-47c1-adf8-2db376642f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRF(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(CRF, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        # Transisi dari label i ke label j (transisi[i, j] adalah transisi dari i ke j)\n",
    "        self.transitions = nn.Parameter(torch.zeros(num_labels, num_labels))\n",
    "\n",
    "    def forward(self, emissions, tags):\n",
    "        batch_size, sentence_length, _ = emissions.size()\n",
    "\n",
    "        # Compute the unary score\n",
    "        unary_score = emissions.gather(2, tags.unsqueeze(2)).squeeze(2).sum(dim=1)\n",
    "\n",
    "        # Compute the transition score\n",
    "        transition_score = torch.zeros(batch_size)\n",
    "        for i in range(sentence_length - 1):\n",
    "            transition_score += self.transitions[tags[:, i], tags[:, i + 1]]\n",
    "            \n",
    "        # Sum of unary and transition scores\n",
    "        total_score = unary_score + transition_score\n",
    "        \n",
    "        # Compute the partition function (Z)\n",
    "        alpha = self.compute_alpha(emissions)\n",
    "        log_partition = alpha[:, -1, :].logsumexp(dim=1).sum()\n",
    "\n",
    "        # Compute the log likelihood\n",
    "        loss = log_partition - total_score.sum()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def compute_alpha(self, emissions):\n",
    "        batch_size, sentence_length, _ = emissions.size()\n",
    "        alpha = torch.zeros(batch_size, sentence_length, self.num_labels)\n",
    "\n",
    "        # Initialization\n",
    "        alpha[:, 0, :] = emissions[:, 0, :]\n",
    "\n",
    "        # Recursion\n",
    "        for t in range(1, sentence_length):\n",
    "            alpha[:, t, :] = emissions[:, t, :] + torch.logsumexp(alpha[:, t - 1, :] + self.transitions, dim=1)\n",
    "\n",
    "        return alpha\n",
    "\n",
    "    def viterbi_decode(self, emissions):\n",
    "        batch_size, sentence_length, _ = emissions.size()\n",
    "\n",
    "        # Initialize Viterbi variables\n",
    "        delta = torch.zeros(batch_size, sentence_length, self.num_labels)\n",
    "        backpointer = torch.zeros(batch_size, sentence_length, self.num_labels, dtype=torch.long)\n",
    "\n",
    "        # Initialization\n",
    "        delta[:, 0, :] = emissions[:, 0, :]\n",
    "\n",
    "        # Recursion\n",
    "        for t in range(1, sentence_length):\n",
    "            trans_score = delta[:, t - 1, :].unsqueeze(2) + self.transitions\n",
    "            max_scores, backpointer[:, t, :] = trans_score.max(dim=1)\n",
    "            print(trans_score.max(dim=1))\n",
    "            delta[:, t, :] = emissions[:, t, :] + max_scores\n",
    "\n",
    "        # Termination\n",
    "        best_last_tag = delta[:, -1, :].argmax(dim=1)\n",
    "\n",
    "        # Backtrack to find best path using backpointers\n",
    "        best_path = torch.zeros(batch_size, sentence_length, dtype=torch.long)\n",
    "        best_path[:, -1] = best_last_tag\n",
    "\n",
    "        for t in range(sentence_length - 2, -1, -1):\n",
    "            best_path[:, t] = backpointer[:, t + 1, best_path[:, t + 1]]\n",
    "\n",
    "        return best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5f6b5464-0171-4ad4-8b8a-70cf050d0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERMOEE(nn.Module):\n",
    "    def __init__(self, embedding_size, hidden_size, ner_tags, expert_output_size, n_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        torch.manual_seed(34)\n",
    "        \n",
    "        self.encoder = BiLSTM(embedding_size, hidden_size)\n",
    "        self.MoEE = MoEE(ner_tags, hidden_size, expert_output_size, n_heads)\n",
    "        self.CRF = CRF(len(ner_tags))\n",
    "    \n",
    "    def forward(self, x, verbose):\n",
    "        o = self.encoder(x,verbose)\n",
    "        o = self.MoEE(o,verbose)\n",
    "        o = self.CRF(o,torch.Tensor([t_labels]).to(torch.int64))\n",
    "        \n",
    "        return o\n",
    "    \n",
    "    def predict(self, x):\n",
    "        o = self.encoder(x,False)\n",
    "        o = self.MoEE(o,False)\n",
    "        o = self.CRF.viterbi_decode(o)\n",
    "        \n",
    "        return o\n",
    "    \n",
    "    def update_model_parameters(self, x:torch.Tensor):\n",
    "        self.encoder.reset_states()\n",
    "        x.backward()\n",
    "    \n",
    "    def verbose(self):\n",
    "        self.encoder.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "562272d3-3531-4ee0-87cb-e6efbc888411",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NERMOEE(embedding_size, hidden_size, ner_tags, expert_output_size, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "08933af0-0ffa-411a-91bf-664100f22bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(data,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a9bceb7e-d09c-4afc-b05e-451e68d984d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38, 38, 38, 15]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "fcec8376-dc45-47ca-98f8-5d3bf53ee6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([[94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746,\n",
      "         94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746,\n",
      "         94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746,\n",
      "         94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746,\n",
      "         94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746, 94.0746]],\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "         25, 25, 25]]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020,\n",
      "         188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020,\n",
      "         188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020,\n",
      "         188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020,\n",
      "         188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020, 188.3020,\n",
      "         188.3020, 188.3020, 188.3020, 188.3020]], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "         25, 25, 25]]))\n",
      "torch.return_types.max(\n",
      "values=tensor([[282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541,\n",
      "         282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541,\n",
      "         282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541,\n",
      "         282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541,\n",
      "         282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541, 282.8541,\n",
      "         282.8541, 282.8541, 282.8541, 282.8541]], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "         25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
      "         25, 25, 25]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[25, 25, 25, 25]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2e092245-cb72-45e1-b2e1-8d1c3889c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.SGD(model.parameters(),lr=0.000001)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b024e3df-64cd-47cf-889e-d7e39397ca42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(430.4365, grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ca841ea7-e778-4868-9635-8fc20f63671b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(430.4365, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(410.2005, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(389.9785, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(369.7679, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(349.5758, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(329.4908, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(310.5508, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(296.3021, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(284.0937, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(271.1312, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(257.3369, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(242.8905, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(227.9418, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(212.6085, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(197.0051, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(181.7703, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(175.0717, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(175.6732, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(176.1969, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(176.3059, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(176.0400, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(175.4413, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(174.5467, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(173.3881, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(171.9936, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(170.3878, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(168.5923, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(166.6266, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(164.5079, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(162.2513, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(159.8707, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(157.3782, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(154.7850, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(152.1016, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(149.3388, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(146.5102, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(143.6421, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(140.8021, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(138.1697, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(136.0539, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(134.3945, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(132.4399, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(129.8148, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(126.9305, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(124.3217, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(122.0586, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(119.9565, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(117.8910, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(115.8379, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(113.8382, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(111.9481, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(110.1457, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(108.2769, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(106.1937, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(103.9251, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(101.6223, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(99.3854, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(97.2100, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(95.0537, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(92.8894, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(90.7203, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(88.5738, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(86.4817, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(84.4384, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(82.3794, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(80.2359, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(78.0119, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(75.7702, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(73.5584, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(71.3797, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(69.2143, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(67.0447, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(64.8640, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(62.6743, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(60.4796, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(58.2803, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(56.0709, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(53.8449, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(51.6012, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(49.3458, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(47.0870, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(44.8300, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(42.5750, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(40.3186, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(38.0564, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(35.7850, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(33.5026, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(31.2091, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(28.9061, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(26.5963, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(24.2827, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(21.9684, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(19.6561, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(17.3477, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(15.0444, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(12.7461, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(10.4515, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(8.1578, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(5.8669, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(3.6449, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(2.0638, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(2.8458, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(4.6939, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(4.5463, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(2.5758, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.1648, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.4679, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(2.2603, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(2.8024, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(2.9443, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(2.6982, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(2.1380, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.4365, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(0.9738, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.1740, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.7507, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.8638, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.3765, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(0.9194, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(0.8915, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.1137, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.2961, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.3012, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(1.1328, grad_fn=<SubBackward0>)\n",
      "\n",
      "tensor(0.8936, grad_fn=<SubBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(125):\n",
    "    outputs = model(data,False)\n",
    "    print(outputs)\n",
    "    print()\n",
    "    optimizer.zero_grad()\n",
    "    model.update_model_parameters(outputs)\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kernel1",
   "language": "python",
   "name": "kernel1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
